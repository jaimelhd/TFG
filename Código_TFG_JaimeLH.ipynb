{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XMy7k289n2SC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Rutas de los archivos CSV\n",
        "ruta_hora = '/content/HORA.csv'\n",
        "ruta_dia = '/content/DÍA.csv'\n",
        "ruta_edad_sexo = '/content/EDAD Y SEXO.csv'\n",
        "ruta_distrito = '/content/DISTRITO.csv'\n",
        "df_distrito = pd.read_csv(ruta_distrito)\n",
        "ruta_tipo_accidente = '/content/TIPO DE ACCIDENTE.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISTRITO**"
      ],
      "metadata": {
        "id": "SFmA67oqn_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df_distrito = pd.read_csv(ruta_distrito)\n",
        "columns_to_scale = ['Accidentes', 'Heridos', 'Muertos']   #Nos centramos en las columnas numéricas\n",
        "df_distrito_numeric = df_distrito[columns_to_scale]\n",
        "\n",
        "scaler = StandardScaler() #Escalamos los datos\n",
        "df_distrito_scaled = scaler.fit_transform(df_distrito_numeric)\n",
        "\n",
        "sum_of_squared_distances = []\n",
        "K = range(1, 15)\n",
        "\n",
        "# Calculamos la suma de las distancias al cuadrado para diferentes valores de k\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    km = km.fit(df_distrito_scaled)\n",
        "    sum_of_squared_distances.append(km.inertia_)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('Número de Clústeres')\n",
        "plt.ylabel('Suma de las distancias al cuadrado')\n",
        "plt.title('Método del Codo para determinar el K óptimo')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hK5tQn2XoKd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupamos los datos de 'Distrito' sumando los totales de 'Accidentes', 'Heridos' y 'Muertos'\n",
        "df_distrito_aggregated = df_distrito.groupby('Distrito').sum().drop(columns='Año')\n",
        "\n",
        "# Normalizamos los datos mencionados arriba.\n",
        "df_distrito_aggregated_scaled = scaler.fit_transform(df_distrito_aggregated)\n",
        "\n",
        "# Aplicamos K-Means con 4 clústeres en los datos gracias al método del CODO\n",
        "kmeans_aggregated = KMeans(n_clusters=4, random_state=42)\n",
        "kmeans_aggregated.fit(df_distrito_aggregated_scaled)\n",
        "\n",
        "# Asignamos los clústeres optimizados\n",
        "df_distrito_aggregated['Optimal_Cluster'] = kmeans_aggregated.labels_\n",
        "\n",
        "# Calculamos las medias de cada clúster para los datos\n",
        "cluster_means_aggregated = df_distrito_aggregated.groupby('Optimal_Cluster').mean()\n",
        "\n",
        "cluster_means_aggregated"
      ],
      "metadata": {
        "id": "lmxvUSXgoSbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DÍA**"
      ],
      "metadata": {
        "id": "C6VGXAk5ofmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/DÍA.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "U_uMWhEUoi0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "data_grouped = data.groupby('Dia').mean().reset_index()\n",
        "\n",
        "days_order = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n",
        "data_grouped['Dia'] = pd.Categorical(data_grouped['Dia'], categories=days_order, ordered=True)\n",
        "data_grouped = data_grouped.sort_values('Dia')\n",
        "\n",
        "# Prepararamos los datos para el clustering, excluyendo columnas NO numéricas\n",
        "data_clustering_avg = data_grouped.drop('Dia', axis=1)\n",
        "\n",
        "# Clustering jerárquico\n",
        "Z_avg = linkage(data_clustering_avg, method='ward')\n",
        "\n",
        "# Creamos y Mostramos el dendrograma\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(Z_avg, labels=data_grouped['Dia'].values)\n",
        "plt.title('Dendrograma del Clustering Jerárquico con sus medias')\n",
        "plt.xlabel('Día')\n",
        "plt.ylabel('Distancia')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q_kUerSxosRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinamos el número óptimo de clusters en el dendrograma\n",
        "from scipy.cluster.hierarchy import inconsistent\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "# Profundidad para el cálculo de inconsistencia\n",
        "depth = 2\n",
        "incons = inconsistent(Z_avg, depth)\n",
        "incons[-10:]  # Mostramos las últimas 10 inconsistencias para evaluar\n",
        "\n",
        "k = 2\n",
        "clusters = fcluster(Z_avg, k, criterion='maxclust')\n",
        "data_grouped['Cluster'] = clusters\n",
        "data_grouped[['Dia', 'Cluster']].sort_values('Cluster')"
      ],
      "metadata": {
        "id": "ZZZn-xEoo-PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos la media de accidentes, heridos y muertos para cada cluster\n",
        "cluster_averages = data_grouped.groupby('Cluster')['Accidentes', 'Heridos', 'Muertos'].mean()\n",
        "cluster_averages"
      ],
      "metadata": {
        "id": "NJPYRe0qrGLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aquí identificamos el día con el mayor número de accidentes, heridos y muertos dentro de cada cluster\n",
        "max_values_per_cluster = data_grouped.groupby('Cluster').apply(lambda x: x.nlargest(1, ['Accidentes', 'Heridos', 'Muertos']))\n",
        "max_values_per_cluster[['Dia', 'Accidentes', 'Heridos', 'Muertos']].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "PgNVLAPorJsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "# Como antes, creamos la variable Severidad combinando los datos de DÍA (sumando heridos y muertos)\n",
        "dia_data['Severidad'] = dia_data['Heridos'] + dia_data['Muertos']\n",
        "\n",
        "# Visualizamos la severidad de los accidentes por día de la semana\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Dia', y='Severidad', data=dia_data, palette='coolwarm', order=['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo'])\n",
        "plt.title('GRAVEDAD de los Accidentes por Día de la Semana')\n",
        "plt.xlabel('Día de la Semana')\n",
        "plt.ylabel('Severidad (Heridos + Muertos)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hG2P2WV6rbEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HORA**"
      ],
      "metadata": {
        "id": "RkDZdujit2po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv('/content/HORA.csv')\n",
        "\n",
        "# Arupamos los datos de la columna 'Hora' calculando la suma de 'Accidentes', 'Heridos', y 'Muertos'\n",
        "grouped_data = data.groupby('Hora').agg({'Accidentes': 'sum', 'Heridos': 'sum', 'Muertos': 'sum'}).reset_index()\n",
        "\n",
        "# Prepararamos los datos para el clustering\n",
        "X = grouped_data[['Accidentes', 'Heridos', 'Muertos']]\n",
        "\n",
        "# Escalamos los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Clustering jerárquico\n",
        "Z = linkage(X_scaled, method='ward')\n",
        "\n",
        "# Dibujamos el dendrograma\n",
        "plt.figure(figsize=(10, 8))\n",
        "dendrogram(Z, labels=grouped_data['Hora'].values, leaf_rotation=90, leaf_font_size=10)\n",
        "plt.title(\"Dendrograma del Clustering Jerárquico\")\n",
        "plt.xlabel(\"Hora\")\n",
        "plt.ylabel(\"Distancia\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_RPbqhpRt43N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "\n",
        "k = 4  # VIENDO EL DENDOGRAMA, CONSIDERAMOS QUE HAY 4\n",
        "\n",
        "# Asignamos los clusters a cada observación\n",
        "clusters = fcluster(Z, k, criterion='maxclust')\n",
        "\n",
        "grouped_data['Cluster'] = clusters\n",
        "\n",
        "# Calculamos la media de accidentes, heridos y muertos por cluster\n",
        "cluster_means = grouped_data.groupby('Cluster').agg({'Accidentes': 'mean', 'Heridos': 'mean', 'Muertos': 'mean'}).reset_index()\n",
        "\n",
        "cluster_means"
      ],
      "metadata": {
        "id": "thWje8KjuDaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un resumen que muestre las horas que pertenecen a cada cluster\n",
        "cluster_hours = grouped_data.groupby('Cluster')['Hora'].apply(list).reset_index()\n",
        "\n",
        "cluster_hours"
      ],
      "metadata": {
        "id": "hN7uzfecuT8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cluster_hours = pd.DataFrame({\n",
        "    'Cluster': [1, 2, 3, 4],\n",
        "    'Horas': [\n",
        "        ['De 00 a 01', 'De 01 a 02', 'De 02 a 03', 'De 03 a 04', 'De 04 a 05', 'De 05 a 06', 'De 06 a 07'],\n",
        "        ['De 14 a 15', 'De 20 a 21', 'De 21 a 22'],\n",
        "        ['De 07 a 08', 'De 08 a 09', 'De 10 a 11', 'De 22 a 23', 'De 23 a 24'],\n",
        "        ['De 09 a 10', 'De 11 a 12', 'De 12 a 13', 'De 13 a 14', 'De 15 a 16', 'De 16 a 17', 'De 17 a 18', 'De 18 a 19', 'De 19 a 20']\n",
        "    ]\n",
        "})\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cluster_data = {\n",
        "    'Cluster 1': ['De 00 a 01', 'De 01 a 02', 'De 02 a 03', 'De 03 a 04', 'De 04 a 05', 'De 05 a 06', 'De 06 a 07'],\n",
        "    'Cluster 2': ['De 14 a 15', 'De 20 a 21', 'De 21 a 22'],\n",
        "    'Cluster 3': ['De 07 a 08', 'De 08 a 09', 'De 10 a 11', 'De 22 a 23', 'De 23 a 24'],\n",
        "    'Cluster 4': ['De 09 a 10', 'De 11 a 12', 'De 12 a 13', 'De 13 a 14', 'De 15 a 16', 'De 16 a 17', 'De 17 a 18', 'De 18 a 19', 'De 19 a 20']\n",
        "}\n",
        "\n",
        "# Convertimos los rangos horarios a valores numéricos para el eje X (solo la hora de inicio)\n",
        "num_hours = {time_range: int(time_range.split(' ')[1].split('a')[0]) for cluster in cluster_data.values() for time_range in cluster}\n",
        "\n",
        "# Prepararamos los datos para el gráfico\n",
        "x_vals = []\n",
        "y_vals = []\n",
        "sizes = []\n",
        "labels = []\n",
        "\n",
        "for cluster, hours in cluster_data.items():\n",
        "    for hour in hours:\n",
        "        x_vals.append(num_hours[hour])\n",
        "        y_vals.append(cluster)\n",
        "        sizes.append(300)  # tamaño constante para todos los puntos a 300\n",
        "\n",
        "# Creamos el gráfico de dispersión\n",
        "plt.figure(figsize=(14, 6))\n",
        "scatter = plt.scatter(x_vals, y_vals, s=sizes, c=np.arange(len(x_vals)), cmap=\"viridis\", alpha=0.6, edgecolors=\"w\", linewidth=0.5)\n",
        "\n",
        "# Añadimos las etiquetas de hora a los puntos\n",
        "for i, label in enumerate(labels):\n",
        "    plt.annotate(label, (x_vals[i], y_vals[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "\n",
        "plt.title('Distribución Horaria por Cluster')\n",
        "plt.xlabel('Hora del Día')\n",
        "plt.ylabel('Cluster')\n",
        "plt.yticks([cluster for cluster in cluster_data.keys()])\n",
        "plt.xticks(range(0, 24), [f'{i}:00' for i in range(0, 24)], rotation=90)  # cada hora del día\n",
        "plt.grid(True, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5nUdcFGguZ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDAD Y SEXO**"
      ],
      "metadata": {
        "id": "UQkpMfyeutOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "archivo = '/content/EDAD Y SEXO.csv'\n",
        "data = pd.read_csv(archivo)"
      ],
      "metadata": {
        "id": "xOrChVo-uz-r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "sns.barplot(data=data, x='Rango Edad', y='Accidentes Ambos Sexos', color='blue', label='Accidentes')\n",
        "sns.barplot(data=data, x='Rango Edad', y='Heridos Ambos Sexos', color='orange', label='Heridos')\n",
        "sns.barplot(data=data, x='Rango Edad', y='Muertos Ambos Sexos', color='red', label='Muertos')\n",
        "\n",
        "plt.title('Accidentes, Heridos y Muertos por Rango de Edad')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Cantidad')\n",
        "plt.xlabel('Rango de Edad')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nsVt4K6IvDWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Accidentes a lo largo del tiempo por rango de edad\n",
        "sns.lineplot(data=data, x='Año', y='Accidentes Ambos Sexos', hue='Rango Edad', marker='o', palette='tab10', linewidth=2.5)\n",
        "\n",
        "plt.title('Evolución de los Accidentes por Rango de Edad a lo Largo del Tiempo')\n",
        "plt.xlabel('Año')\n",
        "plt.ylabel('Número de Accidentes')\n",
        "plt.legend(title='Rango de Edad', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QWUQeCc4vOvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TIPO DE ACCIDENTE**"
      ],
      "metadata": {
        "id": "xLm72qT8vSMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = '/content/TIPO DE ACCIDENTE.csv'\n",
        "data = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "-fKWZC6TvYTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seleccionamos solo las columnas numéricas para el clustering\n",
        "data_clustering = data[['Accidentes', 'Heridos', 'Muertos']]\n",
        "\n",
        "# Normalizamos las variables\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data_clustering)\n",
        "\n",
        "# Método del codo para determinar el número óptimo de clusters\n",
        "sse = []\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(data_normalized)\n",
        "    sse.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), sse, marker='o')\n",
        "plt.title('Método del Codo para Determinar el Número Óptimo de Clusters')\n",
        "plt.xlabel('Número de Clusters')\n",
        "plt.ylabel('SSE (Suma de Cuadrados de las Distancias)')\n",
        "plt.xticks(range(1, 11))\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqc_HDbjvbW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupamos por 'Tipo de Accidente' y calculamos la media de las variables numéricas\n",
        "data_aggregated = data.groupby('Tipo de Accidente').agg({'Accidentes': 'mean', 'Heridos': 'mean', 'Muertos': 'mean'}).reset_index()\n",
        "\n",
        "# Normalizamos los datos agrupados\n",
        "data_aggregated_normalized = scaler.fit_transform(data_aggregated[['Accidentes', 'Heridos', 'Muertos']])\n",
        "\n",
        "# Aplicamos KMeans con 3 clusters a los datos agrupados y normalizados\n",
        "kmeans_aggregated = KMeans(n_clusters=3, random_state=42)\n",
        "data_aggregated['Cluster'] = kmeans_aggregated.fit_predict(data_aggregated_normalized)\n",
        "\n",
        "clusters_summary_aggregated = data_aggregated.groupby('Cluster').agg(\n",
        "    {'Accidentes': ['mean', 'min', 'max'],\n",
        "     'Heridos': ['mean', 'min', 'max'],\n",
        "     'Muertos': ['mean', 'min', 'max'],\n",
        "     'Tipo de Accidente': 'count'}\n",
        ").rename(columns={'Tipo de Accidente': 'Cantidad de Tipos de Accidente'})\n",
        "\n",
        "clusters_summary_aggregated.round(2)"
      ],
      "metadata": {
        "id": "yO_tuBaTvoAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos los tipos de accidentes en cada cluster\n",
        "tipos_de_accidente_por_cluster = data_aggregated.groupby('Cluster')['Tipo de Accidente'].apply(list).reset_index()\n",
        "\n",
        "tipos_de_accidente_por_cluster"
      ],
      "metadata": {
        "id": "yMBV4_tsvsVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "# Reducción de dimensionalidad para la visualización\n",
        "pca = PCA(n_components=2)\n",
        "data_pca = pca.fit_transform(data_aggregated_normalized)\n",
        "\n",
        "# Agregamos las componentes principales al dataframe\n",
        "data_aggregated['PC1'] = data_pca[:, 0]\n",
        "data_aggregated['PC2'] = data_pca[:, 1]\n",
        "\n",
        "# Gráfico de dispersión de los clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(data=data_aggregated, x='PC1', y='PC2', hue='Cluster', palette='viridis', s=100, alpha=0.7, legend=\"full\")\n",
        "\n",
        "for i, txt in enumerate(data_aggregated['Tipo de Accidente']):\n",
        "    plt.annotate(txt, (data_aggregated['PC1'][i], data_aggregated['PC2'][i]), textcoords=\"offset points\", xytext=(0,10), ha='center', size=8)\n",
        "\n",
        "plt.title('Visualización de Clusters de Tipos de Accidente con PCA')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(title='Cluster')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2uhW8R-SvvoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}